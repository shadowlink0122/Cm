# メモリアクセス最適化とデータ構造の選択

## 概要
行列計算ベンチマークから判明した、Cm言語のメモリアクセス最適化とデータ構造選択の重要性について分析します。

## 実験結果

### データ構造別パフォーマンス（500×500行列）

| データ構造 | 実行時間 | C++比 | 特徴 |
|-----------|---------|-------|------|
| 固定配列（スタック） | 14.55秒 | 30倍遅い | 巨大スタック（3MB） |
| malloc + IKJ順 | 0.11秒 | 4倍速い | キャッシュ効率的 |
| 構造体ラップ | 0.10秒 | 4.8倍速い | アクセス関数でカプセル化 |
| C++ vector | 0.48秒 | 基準 | STLコンテナ |
| Rust Vec | 0.51秒 | 1.06倍 | 所有権システム |

## メモリアクセスパターンの影響

### 1. キャッシュミスの影響

```cm
// 悪い例：IJK順（キャッシュミス多発）
for (int i = 0; i < n; i++) {
    for (int j = 0; j < n; j++) {
        for (int k = 0; k < n; k++) {
            // b[k][j]がkループで列方向にアクセス
            c[i][j] += a[i][k] * b[k][j];
        }
    }
}
```

**問題点**：
- `b[k][j]`が列方向アクセス（ストライド = n×4バイト）
- キャッシュライン（64バイト）を無駄にする
- メモリ帯域幅の非効率的な使用

### 2. キャッシュ効率的なアクセス

```cm
// 良い例：IKJ順（キャッシュ効率的）
for (int i = 0; i < n; i++) {
    for (int k = 0; k < n; k++) {
        int a_ik = a[i][k];  // 一度読んで再利用
        for (int j = 0; j < n; j++) {
            // b[k][j]が行方向アクセス（連続）
            c[i][j] += a_ik * b[k][j];
        }
    }
}
```

**改善点**：
- `b[k][j]`が行方向アクセス（連続メモリ）
- `a[i][k]`をレジスタに保持
- キャッシュライン全体を有効活用

## メモリ階層とアクセスコスト

### レイテンシ比較（典型的なx86-64）

| メモリ階層 | レイテンシ | サイズ | 比率 |
|-----------|----------|--------|------|
| L1キャッシュ | 1ns | 32KB | 1x |
| L2キャッシュ | 4ns | 256KB | 4x |
| L3キャッシュ | 12ns | 8MB | 12x |
| メインメモリ | 100ns | 16GB | 100x |

### 行列計算での影響

500×500行列（int型）のメモリ使用量：
- 1行列 = 500 × 500 × 4バイト = 1MB
- 3行列 = 3MB

**キャッシュ効率**：
- L3（8MB）に3行列すべて収まる
- ただし、アクセスパターンが重要

## データ構造設計の指針

### 1. 配列 vs ポインタ

```cm
// 配列（スタック）
int[500][500] matrix;  // 連続メモリ、スタックサイズ制限

// ポインタ（ヒープ）
int* matrix = malloc(500 * 500 * sizeof(int));  // 柔軟、間接参照
```

### 2. 構造体によるカプセル化

```cm
struct Matrix {
    int* data;
    int rows;
    int cols;

    // アクセスメソッド
    int get(int i, int j) {
        return data[i * cols + j];
    }
}
```

**利点**：
- 抽象化による保守性
- 境界チェック可能
- 最適化の隠蔽

### 3. スライス（動的配列）の活用

```cm
// 理想的なスライス実装（将来）
int[][] matrix = new int[500][500];  // 2次元スライス

// 現状の代替案
struct Matrix2D {
    int[] data;     // 1次元スライス
    int rows;
    int cols;
}
```

## 最適化技術

### 1. ループタイリング（ブロック化）

```cm
const int BLOCK = 64;  // L1キャッシュサイズに合わせる

for (int ii = 0; ii < n; ii += BLOCK) {
    for (int kk = 0; kk < n; kk += BLOCK) {
        for (int jj = 0; jj < n; jj += BLOCK) {
            // ブロック内処理
            for (int i = ii; i < min(ii + BLOCK, n); i++) {
                for (int k = kk; k < min(kk + BLOCK, n); k++) {
                    int a_ik = a[i * n + k];
                    for (int j = jj; j < min(jj + BLOCK, n); j++) {
                        c[i * n + j] += a_ik * b[k * n + j];
                    }
                }
            }
        }
    }
}
```

### 2. プリフェッチ

```cm
// 将来的な実装
#pragma prefetch(b[k+1])
for (int k = 0; k < n; k++) {
    // 次のイテレーションのデータを先読み
}
```

### 3. SIMD化

```cm
// 将来的な実装
#pragma simd
for (int j = 0; j < n; j += 4) {
    // 4要素同時処理
}
```

## Cm言語への提言

### 短期改善案

1. **自動ヒープ割り当て**
   ```cm
   // コンパイラが自動判定
   int[1000][1000] large;  // → 自動的にヒープへ
   int[10][10] small;      // → スタックのまま
   ```

2. **多次元スライスのサポート**
   ```cm
   int[][] matrix = [][];  // 2次元動的配列
   matrix.resize(500, 500);
   ```

3. **行列演算ライブラリ**
   ```cm
   import std::matrix;
   Matrix a(500, 500);
   Matrix c = a * b;  // 最適化された実装
   ```

### 中期改善案

1. **キャッシュアウェアなコンテナ**
   ```cm
   CacheAlignedMatrix<int, 500, 500> matrix;
   ```

2. **並列化サポート**
   ```cm
   #pragma parallel for
   for (int i = 0; i < n; i++) {
       // 自動並列化
   }
   ```

### 長期改善案

1. **JITによる動的最適化**
   - 実行時のキャッシュサイズ検出
   - 最適なブロックサイズの自動選択

2. **GPU/SIMD自動化**
   - 行列演算の自動GPU化
   - SIMD命令の自動生成

## ベンチマーク改善の実例

### Before（固定配列）
```cm
void matrix_multiply(int n) {
    int[500][500] a;  // スタック3MB
    int[500][500] b;
    int[500][500] c;
    // IJK順、14.55秒
}
```

### After（最適化版）
```cm
void matrix_multiply(int n) {
    int* a = malloc(n * n * sizeof(int));  // ヒープ
    int* b = malloc(n * n * sizeof(int));
    int* c = malloc(n * n * sizeof(int));

    // IKJ順でキャッシュ効率化
    for (int i = 0; i < n; i++) {
        for (int k = 0; k < n; k++) {
            int a_ik = a[i * n + k];
            for (int j = 0; j < n; j++) {
                c[i * n + j] += a_ik * b[k * n + j];
            }
        }
    }
    // 0.11秒（130倍高速化）
}
```

## 結論

1. **メモリアクセスパターンが性能を決定**
   - IJK順 vs IKJ順で10倍以上の差
   - キャッシュ効率が最重要

2. **データ構造の選択が重要**
   - 大きな配列はヒープへ
   - 構造体でカプセル化
   - 将来的にはスライスの活用

3. **コンパイラ最適化の余地**
   - 自動的なメモリ配置最適化
   - ループ変換の自動化
   - SIMD/並列化の自動適用

これらの最適化により、Cm言語でもC++/Rustと同等以上の性能を実現できることが実証されました。